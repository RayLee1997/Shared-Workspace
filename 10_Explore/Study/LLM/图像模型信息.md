# 图像模型信息（调研/验证记录）

更新时间：2026-01-23

本文件聚焦两件事：

1. GitHub Copilot 是否/有哪些「文本生成图像（Text-to-Image, T2I）」模型可用
2. 在 OpenCode 工作流里做「文档插图」时，可用的 AI 工具/模型与最佳实践

---

## 1) 目前 GitHub Copilot 可用的「文本生成图像」模型有哪些？

结论：目前 **GitHub Copilot（产品本身）不提供可直接调用的 T2I（文本生图）模型能力**，因此「可用模型列表」为：**无**。

### 验证依据（可复核）

- GitHub Copilot 官方产品页介绍的是代码/聊天/代理等能力与“可选择多种 LLM”，未描述“文本生成图像/图像生成模型/生成图片”能力：`https://github.com/features/copilot`
- GitHub Changelog（2026 年 RSS）中未检索到 Copilot 的“text-to-image / DALL·E / image generation / image models / Copilot Vision”等相关条目（关键词已对齐）：`https://github.blog/changelog/feed/`

补充（核对 GitHub 官方模型列表命名）：

- GitHub Docs 的 Copilot 官方模型列表目前包含 `Gemini 2.5 Pro`、`Gemini 3 Flash`、`Gemini 3 Pro`，**不包含** `Gemini 3 Nano` 或任何带 `banana` 字样的模型：`https://docs.github.com/en/copilot/reference/ai-models/supported-models`

### 相关澄清（避免混淆）

- Copilot 支持“选择不同 LLM”通常指 **文本/代码模型**（例如用于 Chat、Agent、补全等）。
- “图像输入理解（vision）”与“文本生成图像（T2I）”是两类能力；即使某些客户端支持图像输入理解，也不等价于提供 T2I 模型。

### 如果你确实需要在“Copilot 生态”里生成图片

- 通常需要使用 **其他产品/服务**（例如独立的图像生成服务或本地工作流），Copilot/LLM 负责：
  - 产出 prompt、风格规范、分镜/构图描述
  - 产出可渲染的“图表即代码”（Mermaid/PlantUML）替代部分插图需求

---

## 2) OpenCode 可用的文档插图 AI 工具和模型：最佳实践

### OpenCode 在“做插图”这件事上能提供什么

OpenCode 本身是编码/自动化代理，不内置“图片生成引擎”，但它具备两点让“文档插图工作流”很好落地：

- 可连接多种模型/账号（含 GitHub Copilot），用于写作、提示词、图示脚本生成：`https://opencode.ai/docs/providers/`
- 可通过 MCP（Model Context Protocol）接入外部工具（包括：调用在线 T2I、调用本地 ComfyUI/A1111、做图片压缩/转换等），让“生成图片”成为可被 agent 调用的工具：`https://opencode.ai/docs/mcp-servers/`

（OpenCode 工具系统概览：`https://opencode.ai/docs/tools/`）

---

### 文档插图优先级（推荐）

按“可维护性/可版本化/可复用/可读性”从高到低：

1. **图表即代码（Diagram-as-Code）**：Mermaid、PlantUML、Graphviz
2. **矢量图（SVG）**：图标/结构图/流程图优先 SVG
3. **位图（PNG/WebP）**：需要氛围/具象示意/封面风格时用

原因：前两者可直接进 Git、diff 友好、可在 Obsidian/Markdown 里长期维护。

---

### 可用工具/模型（按场景列举）

#### A. 图表/架构图（优先用“文本→可渲染代码”）

- 工具：Mermaid / PlantUML / Graphviz
- 生成方式：用 OpenCode 让 LLM 产出图表源码（.md / .mmd / .puml），再由渲染器生成 SVG/PNG
- 适用：流程、时序、组件依赖、状态机、数据流

#### B. 文档配图（位图：概念插画、封面、场景示意）

OpenCode 侧重点是把“生成图像”外包给工具（API/本地），自己负责 prompt、规范、批量化与落盘。

常见可选 T2I 模型（按生态分类，实际以你能接入的服务为准）：

- 商业云：OpenAI DALL·E 3、Midjourney、Ideogram、Adobe Firefly
- 开源/本地：SDXL（Stable Diffusion XL）、FLUX 系列（Black Forest Labs）、以及它们的社区微调模型

#### C. 图标/贴纸/小组件（尽量输出 SVG 或高分辨率透明底 PNG）

- 常用：Ideogram/Firefly（文字排版与图形感更友好），或本地 SDXL/FLUX 走一致风格
- 重点：统一线宽、圆角、阴影规则；避免每张图风格漂移

---

### 最佳实践（可直接套用）

#### 1) 先定“插图规范”，再批量出图

建议把以下内容写进你的项目规范（或 Obsidian vault 的约定）：

- 画布：常用宽度（例如 1200px）、比例（16:9 / 4:3 / 1:1）
- 风格：配色（3-5 个主色）、线条/质感（扁平/拟物/颗粒/等距）
- 一致性：固定光源方向、阴影层级、背景纹理强度

#### 2) Prompt 模板（把变量显式化）

用于“概念插画”的模板（给任何 T2I 都好用）：

```text
主题：{一句话讲清楚}
用途：文档插图（说明 {概念/流程/组件}）
构图：{主体位置/留白区域/视角}
风格：{扁平/等距/线稿/3D/颗粒感}，{配色}，{背景}
约束：无文字/少文字；边缘干净；高对比便于缩略图；不要水印
输出：{尺寸}，{是否透明底}
```

#### 3) 用 OpenCode 把“生成图”变成可重复的命令

推荐两条路线（都能被 OpenCode 自动化）：

- **MCP 路线（更像“工具”）**：写/引入一个 image-gen MCP server（调用 DALL·E/SDXL/ComfyUI API），在 OpenCode 里当工具用；优点是权限/工具列表统一管理。
- **脚本路线（更像“流水线”）**：用 `bash` 工具调用本地脚本（curl 调 ComfyUI、python 调 API），把图片写入固定目录。

#### 4) 产物落盘与可追溯

- 路径建议：`assets/images/` 或笔记同级 `assets/`
- 命名建议：`YYYYMMDD_topic_style_v1.png`（或加 hash）
- 建议同时保存：
  - `*.prompt.md`：最终 prompt + 参数（尺寸、seed、cfg、steps、model、lora 等）
  - `*.src.json`：如果是 ComfyUI workflow/节点图，直接存 JSON

#### 5) Obsidian/Markdown 可读性

- 每张图都写 alt text（便于检索与无障碍）：`![alt](path)`
- 优先 SVG（图表/结构图），位图尽量压到可接受体积（WebP/PNG 优化）

---

## 附：与 OpenCode 集成插图工具的示例思路（MCP）

目标：把“生成图片”变成 OpenCode 可调用的工具。

1. 实现/引入一个 MCP server（本地或远程），提供类似：
   - `image_generate(prompt, width, height, format, transparent, seed, model)`
   - `image_variation(image_path, prompt, strength, seed, ...)`
2. 在 `opencode.json` 增加 MCP 配置（见 OpenCode MCP 文档）：`https://opencode.ai/docs/mcp-servers/`
3. 让 OpenCode：
   - 先产出 prompt + 参数
   - 调 MCP 生成
   - 自动落盘到文档目录并在 Markdown 里插入链接
