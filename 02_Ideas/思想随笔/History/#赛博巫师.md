#赛博巫师

1. 使用阿里的开源 Qwen3 系列搭建 Deep Researcher。在 Planning 和 Executor 开关一下 Thinking 模式，主要工作集中在 ReAct 模式的调试上。其综合能力可以说稳居第二梯队的前两名。音视频领域，Wan2.x 系列目前的体验相当不错，创建 5～10秒的 Image2Video 使用场景，配合 Juggernaut SDXL 出图，无论是生成单镜头动画还是姿态控制动画，最后经镜头拼接，基本已迈入生产级状态；
    
2. 另外就是简中社区相对陌生的开源玩家 Google Gemma 系列，可能是狗狗家旗舰模型 Gemini 太过耀眼，Gemma 像是不存在一样的东西。晚上拉了 Hugging Face 的模型列表看了一下，整体感觉它与 Gemini 走了截然相反的路线：Gemini 更追求单一模型的通用性，而 Gemma 系列更像是零件仓库，按模型擅长的职能拆分得无比细致。这种特性反而更适合通过 ComfyUI 这类工作流进行组装，以适配不同场景下 Auto Agent 的要求；
    
3. 比如实现 Deep Researcher，采用本地知识库 + Google Search API 的方案，Embedding Gemma 负责向量化 + Gemma3 27B 负责 Planning 和 Review + Function Gemma 负责意图识别与工具调用 + Translate Gemma 负责多语言转换。整套方案本地部署的 vRAM 大概 20GB 上下；
    
4. 如果是视频自动解读这类的解决方案，Whisper 提取 SRT + SigLIP 识别与提取视频关键帧 + Gemma 3 推理分析 + Translate Gemma 多语言转换 + GPT-SoVITS 语音克隆。本地部署开销大概 16GB vRAM，还能用上 vLLM 的推理加速；
    
5. 最后，这两天发现了一家算力界的拼多多，AutoDL，训练任务完全可以扔给云端。A6000 PRO  96GB vRAM 1小时只要5块钱，连上SSH Tunnel 映射端口，本地开发体验 + 云端运行效率，妈妈再也不用担心你的 OOM 了，hhh…
    

码农这个职业已经消失了，这是赛博巫师的时代，作为前资深码农，从未感受过如此轻松随意的算力调度能力，就像神话中的萨满巫师一样，在 Cyber 世界里可以这么轻易的呼风唤雨…

[偷笑]