# Amazon.com, Inc. (AMZN) 深度分析报告

> **分析日期**: 2026-02-06
> **分析周期**: FY 2025 (Q1-Q4)
> **报告类型**: 深度研究 / Earnings Review (SEC 数据验证)
> **分析师**: Digital Ray / Antigravity Agent

---

## 📌 Executive Summary（核心摘要）

### 一句话结论

Amazon 依然是全球电商与云计算领域的绝对霸主，AWS 增长重新加速 (+24%)、利润率扩张至 35%。然而，公司宣布 **2026 年 Capex 将达 $200B**，这一"天文数字"引发市场对短期 Free Cash Flow 的剧烈担忧，导致财报后股价暴跌 ~14%。

### 核心发现

| 维度 | 评估 | 要点 |
|:---|:---|:---|
| **财务健康** | 🟡 **中性** | Revenue 增长稳健 ($704.6B, +13%)，但巨额 Capex (2025: ~$131B, 2026: ~$200B) 将严重压制短期 FCF。 |
| **成长动能** | 🟢 **强劲** | AWS Q4 Revenue $36.2B，Margin 35%，GenAI 业务已达"数十亿美元"级别；广告业务贡献 $12B 增量。 |
| **AI 护城河** | 🟢 **深阔** | AWS Trainium2/3 自研芯片生态成型，Anthropic 深度绑定，算力基础设施规模领跑行业。 |

### 投资观点

**评级**：**长期看好 / 短期波动**

* **短期**: $200B 资本开支不仅是数字冲击，更意味着折旧摊销将拖累未来几个季度的 Operating Income。
* **长期**: 这种规模的投入构建了极高的竞争壁垒 (Scale Advantage)。如果 AI 需求如 Jassy 所言是"供给受限"的，那么现在的激进投入将在 2027+ 转化为垄断级利润。

---

## 🏗️ AWS 资本开支 (Capex) 深度解析

### 1. 2026 年 $200B Capex 意味着什么？

Amazon 宣布 2026 年预计资本支出约为 **$2000 亿美元**。

* **对比 2025**: ~$131B（增长 ~53%）。
* **对比历史**: 2024 年仅为 ~$50-60B，两年内翻了近 4 倍。
* **对比竞对**: 远超 Microsoft (~$80B)、Google (~$75B) 和 Meta (~$65B) 的 2025 年预期支出。**Amazon 一家的 Capex 几乎等于 Google 和 Microsoft 之和。**

### 2. 钱花在哪里？(Capex Breakdown)

根据 Jassy 电话会及分析师 (UBS, BofA) 测算，这 $200B 的巨额投入并非均匀分布，而是 **All-in AWS**：

| 投资领域 | 预估占比 (整体) | 细分投向 (AWS 内部) | 数额估算 | 核心用途 |
|:---|:---|:---|:---|:---|
| **AWS 基础设施** | **~75-80%** | - 数据中心建设: ~30-35%<br>- 服务器与网络: ~35-40%<br>- 自研芯片产能: ~10-15% | **~$150-160B** | **AI 数据中心** (Real Estate/Power)、**Trainium/GPU 集群**、**网络互联**。 |
| **物流履约** | ~10-15% | - | ~$20-30B | 自动化仓储机器人、Same-day 配送网络优化、车辆。 |
| **Kuiper 卫星** | ~5-15% | - | ~$10-30B* | LEO 卫星发射与制造 (2026 是密集发射年)。 |

*\*注：Kuiper 和物流的占比不同机构预测略有波动，但 AWS 占据 3/4 以上是共识。*

**关键结论**: 这个 CapEx 计划显示了 Amazon 最激进的战略重心转移。Jassy 明确表示 AWS 的投入大部分是为了满足**已经签约的积压订单 (Backlog)**，而非盲目建设。

### 3. 财务影响分析

* **Free Cash Flow (FCF)**: 短期内将转负或大幅缩减。这是股价暴跌的核心原因——市场习惯了 Amazon 作为"现金牛"，现在再次进入"投入期"。
* **折旧 (Depreciation)**: 巨额服务器投入通常分 3-5 年折旧。这意味着 2026-2027 年的 Operating Margin 会受到新增折旧费用的显著拖累。
* **供应受限 (Supply Constrained)**: 管理层反复强调"需求 > 产能"。这意味着只要产能上线，立刻就能转化为 Revenue。这与"建成空置"的风险有本质区别。

---

## 📊 FY 2025 季度财务数据（SEC 验证）

> **数据来源**: Q1-Q3 SEC 10-Q；Q4 SEC 8-K (2026.02.05)

### Quarterly Financial Summary

| 指标 | Q1 2025 | Q2 2025 | Q3 2025 | Q4 2025 | FY 2025 合计 |
|:---|:---|:---|:---|:---|:---|
| **Total Revenue** | $143.3 B | $167.7 B | $180.2 B | **$213.4 B** | **~$704.6 B** |
| *YoY Growth* | +13% | +12% | +12% | +14% | ~13% |
| **AWS Revenue** | $25.0 B | $30.9 B | $27.5 B | **$36.2 B** | **$119.6 B** |
| *AWS YoY* | +17% | +17.5% | +12% | **+24%** | - |
| **Operating Income** | $15.3 B | $19.2 B | $17.4 B* | **~$18.5 B*** | **~$70.4 B** |
| **Net Income** | $17.1 B | $18.2 B | $21.2 B | **$21.19 B** | **$77.7 B** |
| **Diluted EPS** | $1.59 | $1.68 | $1.95 | **$1.95** | **$7.17** |

*\*注: Q3 受 $2.5B FTC 和解费用及 $1.8B 裁员费用影响；Q4 受约 $2.4B 一次性费用影响。*

---

## 📞 Earnings Call CEO 纪要：Andy Jassy 2025 年核心观点

### Q1 2025 — AI 长远愿景

> *"Before this generation of AI, we thought AWS had the chance to ultimately be a multi hundred billion dollar revenue run rate business. With the way AI is developing, I think we could do significantly better."*

* 首次明确表示 AI 可能让 AWS 收入规模远超原来的"数千亿美元"目标。
* 宣布推出 AI 增强版 Alexa Plus。

### Q2 2025 — 需求超出产能

> *"AI is the biggest technology transformation of our lifetime... We have more demand than we have capacity right now."*

* 明确承认 AI 需求已超过 AWS 当前产能，形成"供给限速"增长格局。
* Direct Lane 出货比例同比提升 40%+。

### Q3 2025 — Trainium2 爆发

> *"Trainium2 is fully subscribed and has become a multibillion-dollar business, growing 150% quarter-over-quarter."*

* Trainium2 满负订，季度环比增长 150%。
* Rufus AI 购物助手全年活跃用户 2.5 亿，交互量 YoY +210%。
* AWS Backlog 达 $200B。

### Q4 2025 — $200B Capex 宣言

> *"With such strong demand for our existing offerings and seminal opportunities like AI, chips, robotics, and low earth orbit satellites, we expect to invest about $200 billion in capital expenditures across Amazon in 2026."*

* 这是科技史上单一公司年度资本支出的最高承诺之一。
* AWS Q4 增速 +24%，是过去 13 个季度最快。
* Rufus 用户完成购买可能性提升 60%。

---

## 🔬 关键业务进展深度透视

### 1. AWS：从"云计算"到"AI 基础设施"

**增长重新加速**

* Q4 2025 Revenue +24% YoY，是 AWS 过去 13 个季度最快增速。
* Operating Margin 扩张至 35%（Q3 为 34.6%）。
* AWS Backlog（合同订单额）达 $200B，且 2025年10月签约额超过整个 Q3。

**产能扩张**

* 2025 年全年新增超过 **4GW** 数据中心电力容量。
* Q4 单季新增超过 1GW 容量，是"全球任何云厂商中最大的单季扩张"。

### 2. 零售：效率革命与 AI 赋能

**物流速度**

* 2025 年 Prime 配送超过 **130 亿件商品**，连续第三年刷新"最快配送速度"记录。
* Same-day Perishables（生鲜当日达）覆盖超过 1,000 个美国城市，目标 2025 年底达 2,300 个。

**Rufus AI 购物助手**

* 全年活跃用户 **2.5 亿**，月活 YoY +140%，交互量 YoY +210%。
* 使用 Rufus 的用户完成购买可能性提升 **60%**。
* 功能：产品问答、对比推荐、购物清单生成。

### 3. 广告业务：第三增长极

* 2025 年贡献超过 **$12B 增量收入**。
* Prime Video 广告支持版观众达 **3.15 亿/月**（2024 年中仅 2 亿）。
* Live Sports 广告承诺超预期。

---

## 🤝 Anthropic 战略合作：深度解析

### 合作时间线

| 时间 | 事件 | 金额 / 细节 |
|:---|:---|:---|
| **2023年9月** | 首轮投资 | $1.25B（可扩展至 $4B） |
| **2024年3月** | 第二轮投资 | $2.75B（Amazon 历史上最大外部投资） |
| **2024年3月** | 技术绑定 | Anthropic 承诺使用 Trainium & Inferentia 芯片 |
| **2024年11月** | 第三轮投资 | 额外 $4B，AWS 成为"Primary Training Partner" |
| **2024年11月** | 政府合作 | Anthropic、Palantir、AWS 三方合作为美国政府提供 Claude |
| **2025年中** | Project Rainier 启动 | 开始部署 50 万颗 Trainium2 芯片 |
| **2025年10月** | Claude for Enterprise | Anthropic 在 AWS Marketplace 推出企业版 Claude（$40/用户/月） |
| **2025年12月** | Project Rainier 全面激活 | 近 50 万颗 Trainium2 投入运营 |
| **2025年底（目标）** | 扩容 | 扩展至 **100 万颗** Trainium2 芯片 |
| **2026年2月** | Claude Opus 4.6 | 最新模型在 Amazon Bedrock 上线 |

### 累计投资规模

| 阶段 | 金额 |
|:---|:---|
| 第一轮 (2023.09) | $1.25 B |
| 第二轮 (2024.03) | $2.75 B |
| 第三轮 (2024.11) | $4.0 B |
| **合计** | **$8.0 B** |

**投资回报**：根据 2025 年底的估值，Amazon 持有的 Anthropic 股份公允价值达 **$14B**，账面浮盈约 **$6B**（+75%）。

### 合作内容详解

#### 1. 算力绑定：Project Rainier

* **规模**: 近 **500,000 颗 Trainium2 芯片**，分布在多个美国数据中心。
* **扩容目标**: 2025 年底扩至 **100 万颗**。
* **算力增幅**: 提供 Anthropic 训练前代模型时 **5 倍以上** 的计算能力。
* **架构**: 使用 Trn2 UltraServer（每台含 64 颗 Trainium2，4 台物理服务器合并），通过 NeuronLink 高速互联。
* **地理分布**: 包括印第安纳州园区（30 栋 20 万平方英尺数据中心）。

#### 2. 芯片联合研发

* Anthropic 工程师深度参与 Trainium 底层 Kernel 开发。
* 为 AWS Neuron 软件栈贡献代码。
* **Trainium3** 正在联合研发中，Anthropic 直接提供训练速度、延迟、能效等方面的优化反馈。

#### 3. Amazon Bedrock 分发

* Claude 模型通过 Bedrock 向**数万企业客户**提供服务。
* 支持模型：Claude Opus 4.5/4.6、Sonnet 4.5、Haiku 4.5。
* **Fine-tuning 独占期**: AWS 客户可优先使用 Claude 新模型的定制微调功能。
* 客户案例：Pfizer（制药研发加速）、Intuit（TurboTax 税务解释）、Thomson Reuters（税务指南）、Cox Automotive（汽车销售）。

#### 4. Claude for Enterprise

* 2025年10月在 AWS Marketplace 上线。
* 定价：**$40/用户/月**（最低 25 席位）。
* 定位：即用型企业 AI 协作工具，无需开发。
* 专项方案：金融分析版、生命科学版。

---

## 🤖 AI 战略深度：Amazon 的 AI 投入蓝图

### 1. 自研芯片：Trainium & Inferentia 生态

| 芯片 | 用途 | 代际 | 状态 |
|:---|:---|:---|:---|
| **Trainium** | 模型训练 | Trainium2 (量产)，Trainium3 (研发中) | Trainium2 满负荷 |
| **Inferentia** | 模型推理 | Inferentia2 | 广泛部署 |

**核心优势**:

* 成本效率高于 NVIDIA GPU（在特定工作负载上）。
* 降低对 NVIDIA 的供应链依赖。
* 与 Anthropic 深度绑定，形成技术护城河。

### 2. Amazon Bedrock：企业 AI 平台

* **支持的模型**: Amazon Titan, Claude (Anthropic), Llama (Meta), Stable Diffusion, Command (Cohere)
* **差异化**: 模型选择灵活、Fine-tuning 独占期、VPC 集成、SOC2/HIPAA 合规。

### 3. 零售侧 AI 应用

* **Rufus**: 2.5 亿用户，转化率提升 60%。
* **Alexa Plus**: AI 增强版，支持多轮对话和复杂任务编排。

---

### 📦 附录：AWS Trainium2 芯片深度介绍

#### 概述

**Trainium2** 是 Amazon Web Services (AWS) 旗下 **Annapurna Labs** 设计的第二代 AI 训练芯片，于 2024 年 12 月在 re:Invent 大会上正式 GA（General Availability）。它专为大规模 Generative AI 和 LLM 训练/推理工作负载设计，是 AWS 摆脱 NVIDIA 依赖、构建自研 AI 芯片生态的核心产品。

#### 核心规格

| 参数 | Trainium2 规格 |
|:---|:---|
| **计算性能 (FP8/BF16 Dense)** | **667 TFLOPS** |
| **计算性能 (FP8/BF16 Sparse)** | 316 TFLOPS |
| **内存容量** | **96 GB HBM3e** |
| **内存带宽** | ~2.9 TB/s |
| **功耗** | ~500W |
| **制程** | 5nm |
| **核心数** | 8 个 NeuronCore-V3 |
| **封装** | CoWoS-S/R（双计算小芯片 + 4 个 HBM3e 堆栈） |

#### 架构亮点

**1. NeuronCore-V3 计算核心**

* 每颗 Trainium2 芯片包含 **8 个 NeuronCore-V3** 核心。
* 支持 **Logical NeuronCore Configuration (LNC)**：可将多个物理核心的计算和内存资源合并为单个逻辑核心，灵活适配不同工作负载。

**2. Chiplet 架构**

* 采用 **双计算小芯片 (Dual Compute Chiplets)** 设计，每个小芯片直接连接两个 HBM3e 堆栈。
* 小芯片之间通过 ABF 基板互联，跨芯片访问内存存在轻微性能损失，需 NUMA-aware 编程以达到峰值性能。

**3. NeuronLink 高速互联**

* **Trn2 UltraServer** 将 4 台物理服务器（每台 16 颗 Trainium2）合并为一个逻辑节点，共 **64 颗芯片**。
* 通过 NeuronLink 实现芯片间高速通信，4 倍提升单节点的计算、内存和网络带宽。

**4. EFA 网络扩展**

* Elastic Fabric Adapter (EFA) 基于 AWS Nitro System，提供传输加密且无性能损失。
* 支持扩展到**数十万颗 Trainium2 芯片**的集群规模。

#### 软件生态：AWS Neuron SDK

* **Neuron Kernel Language (NKI)**：类似 NVIDIA CUDA 和 OpenAI Triton 的领域特定语言，允许专家编程者实现接近芯片极限 (Speed of Light, SOL) 的性能。
* **PyTorch & JAX 支持**：通过 XLA 编译器支持主流深度学习框架。
* **Stanford 合作课程**：AWS 与斯坦福大学合作开设 NKI 编程课程，培养 Trainium 开发者生态。

#### 性能对比：Trainium2 vs NVIDIA H100

| 维度 | Trainium2 | NVIDIA H100 (SXM) |
|:---|:---|:---|
| **价格性能比** | AWS 官方宣称 **30-40% 优于 H100** (P5e) | 基准 |
| **内存容量** | 96 GB HBM3e | 80 GB HBM3 |
| **内存带宽** | ~2.9 TB/s | 3.35 TB/s |
| **生态成熟度** | Neuron SDK，生态较新 | CUDA，行业标准 |
| **适用场景** | AWS 原生 LLM 训练/推理，Anthropic 模型 | 通用 AI 工作负载 |

**关键洞察**：

* Trainium2 在特定工作负载（尤其是 AWS 优化的 LLM 训练）上展现出显著成本优势。
* 真实场景下，客户报告称 Trainium2 可实现与 H100 **相似性能但仅需约 25% 成本**。
* 生态成熟度仍是主要劣势，CUDA 的软件优势短期内难以完全被替代。

#### 来源

* [AWS Neuron Documentation: Trainium2 Architecture](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/about-neuron/arch/neuron-hardware/trainium2.html)
* [AWS EC2 Trn2 Instances](https://aws.amazon.com/ec2/instance-types/trn2/)
* [SemiAnalysis: Trainium2 Architecture & Networking](https://newsletter.semianalysis.com/p/amazons-ai-self-sufficiency-trainium2-architecture-networking)

---

### 📦 附录：AWS Trainium3 芯片前瞻

#### 发布概况

在 2025 年 12 月的 re:Invent 大会上，AWS 正式发布了 **Trainium3**，这是其首款采用 **3nm 工艺** 的 AI 芯片，专为 Agentic AI 和推理/训练混合工作负载设计。

#### 核心提升 (vs Trainium2)

| 参数 | Trainium3 规格 | 提升幅度 |
|:---|:---|:---|
| **计算性能 (FP8)** | **2.52 PFLOPS** | **2.0x** |
| **内存容量** | **144 GB HBM3e** | **1.5x** |
| **内存带宽** | **4.9 TB/s** | **1.7x** |
| **制程工艺** | 3nm | (Trn2 为 5nm) |

#### 系统级飞跃：Trn3 UltraServer

* **单节点规模**：扩展至 **144 颗** Trainium3 芯片（Trn2 UltraServer 为 64 颗）。
* **网络架构**：引入 **NeuronSwitch-v1**，实现全互联 (All-to-All) 交换架构。
* **性能收益**：单服务器集群提供 **4.4 倍** 的性能提升和 **4 倍** 的能效优化。

#### 战略意义

Trainium3 的快速迭代（距 Trn2 GA 仅一年）显示了 AWS 在自研芯片领域的激进投入。其设计重点从单纯的算力堆叠转向了支持 **Agentic Workflow** 所需的复杂推理和超大内存带宽，直接对标 NVIDIA Blackwell 架构。

#### 来源

* [AWS re:Invent 2025: Trainium3 Launch](https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-trn3-ultraservers/)
* [TechCrunch: Amazon releases Trainium3](https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/)

---

## ⚠️ 风险分析

| 风险 | 发生概率 | 影响 | 评级 |
|:---|:---|:---|:---|
| FCF "Dead Money" | 高 | 高 | 🔴 |
| Trainium 技术竞争落后 | 中 | 高 | 🔴 |
| Azure + OpenAI 锁定市场 | 中 | 中 | 🟡 |
| 消费放缓拖累零售 | 中 | 中 | 🟡 |
| FTC 反垄断 | 低 | 中 | 🟢 |

---

## 💡 最终结论

**评级**：**长期看好 / 短期谨慎**

**核心逻辑**：AWS Margin 扩张至 35%、Anthropic 合作深度绑定、Trainium2 满负荷运行——这些都证明 AI 需求是真实且可变现的。$200B Capex 短期压制 FCF，但长期构建 AI 基础设施壁垒。14% 的股价暴跌是对 FCF 预期的理性重估，但业务基本面与悲观股价形成矛盾，对于愿意承受 12-18 个月波动的长期投资者，此刻可能是逐步建仓的时机。

---

## 📚 参考来源

### SEC 官方文件

| 文件 | 来源 |
|:---|:---|
| 10-Q (Q1-Q3 2025) | [SEC EDGAR](https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&CIK=1018724&type=10-Q) |
| 8-K (Q4 2025) | [BusinessWire](https://www.businesswire.com/news/home/20260204777163/en/Amazon.com-Announces-Fourth-Quarter-Results) |

### Anthropic 合作

| 来源 | 链接 |
|:---|:---|
| About Amazon: Anthropic Partnership | [Link](https://www.aboutamazon.com/news/aws/amazon-invests-additional-4-billion-anthropic-ai) |
| AWS: Project Rainier | [Link](https://www.aboutamazon.com/news/aws/aws-project-rainier-ai-trainium-chips-compute-cluster) |
| Anthropic: AWS Trainium | [Link](https://www.anthropic.com/news/anthropic-amazon-trainium) |
| SemiAnalysis: AWS AI Resurgence | [Link](https://newsletter.semianalysis.com/p/amazons-ai-resurgence-aws-anthropics-multi-gigawatt-trainium-expansion) |

### Earnings Calls

| 季度 | 来源 |
|:---|:---|
| Q1-Q4 2025 | Investing.com, Seeking Alpha, Motley Fool, CNBC |

---

> ⚠️ **免责声明**
>
> 本报告由 AI 生成，基于公开信息分析，仅供参考研究使用，**不构成任何投资建议**。
> 投资有风险，决策需谨慎。请在做出投资决策前咨询专业投资顾问。
